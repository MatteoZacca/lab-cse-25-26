{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd7243a-b7d3-4e47-b3ec-49cafdebada5",
   "metadata": {},
   "source": [
    "# 101 Spark basics\n",
    "\n",
    "The goal of this lab is to get familiar with Spark programming.\n",
    "\n",
    "- Scala\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "    - [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "    - [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "- Python\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/3.5.0/rdd-programming-guide.html)\n",
    "    - [All RDD APIs](https://spark.apache.org/docs/3.5.0/api/python/reference/api/pyspark.RDD.html)\n",
    "\n",
    "Use `Tab` for autocompletion, `Shift+Tab` for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb4f39692d0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e281923de95ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ea89e32ca9a0:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Local Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Local Spark>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Local Spark\") \\\n",
    "    .config('spark.ui.port', '4040') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a0be28e5e823",
   "metadata": {},
   "source": [
    "## 101-1 Spark warm-up\n",
    "\n",
    "Load the ```capra``` and ```divinacommedia``` datasets and try the following actions:\n",
    "- Show their content (```collect```)\n",
    "- Count their rows (```count```)\n",
    "- Split phrases into words (```map``` or ```flatMap```; what’s the difference?)\n",
    "- Check the results (remember: evaluation is lazy)\n",
    "- Try the ```toDebugString``` function to check the execution plan\n",
    "    - In PySpark, use ```toDebugString().decode(\"unicode_escape\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc4b5cee4a93755",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddCapra = sc.textFile(\"../../../../datasets/capra.txt\")\n",
    "rddDC = sc.textFile(\"../../../../datasets/divinacommedia.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82df92012331ab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sopra', 'la', 'panca', 'la', 'capra', 'campa'],\n",
       " ['sotto', 'la', 'panca', 'la', 'capra', 'crepa']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapraWords1 = rddCapra.map(lambda x : x.split(\" \") )\n",
    "rddCapraWords1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605c9837173b267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapraWords1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277b58790bcfd931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sopra',\n",
       " 'la',\n",
       " 'panca',\n",
       " 'la',\n",
       " 'capra',\n",
       " 'campa',\n",
       " 'sotto',\n",
       " 'la',\n",
       " 'panca',\n",
       " 'la',\n",
       " 'capra',\n",
       " 'crepa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapraWords2 = rddCapra.flatMap(lambda x : x.split(\" \") )\n",
    "rddCapraWords2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37cf925abda9b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapraWords2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251a1761200725bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) PythonRDD[12] at RDD at PythonRDD.scala:53 []\n",
      " |  MapPartitionsRDD[11] at mapPartitions at PythonRDD.scala:160 []\n",
      " |  ShuffledRDD[10] at partitionBy at NativeMethodAccessorImpl.java:0 []\n",
      " +-(1) PairwiseRDD[9] at reduceByKey at /tmp/ipykernel_364/3033110671.py:4 []\n",
      "    |  PythonRDD[8] at reduceByKey at /tmp/ipykernel_364/3033110671.py:4 []\n",
      "    |  ../../../../datasets/capra.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0 []\n",
      "    |  ../../../../datasets/capra.txt HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "rddL = rddCapra. \\\n",
    "   flatMap(lambda x : x.split(\" \") ). \\\n",
    "   map(lambda x : (x,1)). \\\n",
    "   reduceByKey(lambda x,y : x+y)\n",
    "print(rddL.toDebugString().decode(\"unicode_escape\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d04659ace472d8",
   "metadata": {},
   "source": [
    "## 101-2 Basic Spark jobs\n",
    "\n",
    "Implement on Spark the following jobs and test them on both capra and divinacommedia datasets.\n",
    "\n",
    "- **Word count**: count the number of occurrences of each word\n",
    "  - Result: (sopra, 1), (la, 4), …\n",
    "- **Word length count**: count the number of occurrences of words of given lengths\n",
    "  - Result: (2, 4), (5, 8)\n",
    "- Count the average length of words given their first letter (i.e., words that begin with \"s\" have an average length of 5)\n",
    "  - Result: (s, 5), (l, 2), …\n",
    "- Return the inverted index of words (i.e., for each word, list the numbers of lines in which they appear)\n",
    "  - Result: (sopra, (0)), (la, (0, 1)), ...\n",
    "\n",
    "Also, check how sorting works and try to sort key-value RDDs by descending values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab6b26a927a7d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'la'),\n",
       " (2, 'panca'),\n",
       " (2, 'capra'),\n",
       " (1, 'sopra'),\n",
       " (1, 'campa'),\n",
       " (1, 'sotto'),\n",
       " (1, 'crepa')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word count\n",
    "rddCapra. \\\n",
    "  flatMap(lambda x : x.split(\" \") ). \\\n",
    "  map(lambda x : (x,1)). \\\n",
    "  reduceByKey(lambda x,y : x + y). \\\n",
    "  map(lambda kv: (kv[1],kv[0])). \\\n",
    "  sortByKey(False). \\\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a163112f6f1996d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 8), (2, 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word length count\n",
    "rddCapra. \\\n",
    "  flatMap(lambda x : x.split(\" \") ). \\\n",
    "  map(lambda x : (len(x),1)). \\\n",
    "  reduceByKey(lambda x,y : x + y). \\\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f920336ead88eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 5.0), ('l', 2.0), ('p', 5.0), ('c', 5.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average word length by initial\n",
    "rddCapra. \\\n",
    "  flatMap(lambda x : x.split(\" \") ). \\\n",
    "  filter(lambda x : len(x)>0 ). \\\n",
    "  map(lambda x : (x[0:1].lower(), (1,len(x)))). \\\n",
    "  reduceByKey(lambda x, y : (x[0] + y[0], x[1] + y[1])). \\\n",
    "  mapValues(lambda v : v[1]/v[0]). \\\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce60ea554b154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 5.0), ('l', 2.0), ('p', 5.0), ('c', 5.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average word length by initial (alternative on the final map)\n",
    "rddCapra. \\\n",
    "  flatMap(lambda x : x.split(\" \") ). \\\n",
    "  filter(lambda x : len(x)>0 ). \\\n",
    "  map(lambda x : (x[0:1].lower(), (1,len(x)))). \\\n",
    "  reduceByKey(lambda x, y : (x[0] + y[0], x[1] + y[1])). \\\n",
    "  map(lambda kv : (kv[0], kv[1][1]/kv[1][0])). \\\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e2a91002beea79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sopra', [0]),\n",
       " ('la', [1, 3, 7, 9]),\n",
       " ('panca', [2, 8]),\n",
       " ('capra', [4, 10]),\n",
       " ('campa', [5]),\n",
       " ('sotto', [6]),\n",
       " ('crepa', [11])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverted index (word-based offset)\n",
    "rddCapra. \\\n",
    "  flatMap(lambda x : x.split(\" \") ). \\\n",
    "  zipWithIndex(). \\\n",
    "  groupByKey(). \\\n",
    "  mapValues(lambda v: list(v)). \\\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2686f5c972e3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sopra', [0]),\n",
       " ('la', [0, 1]),\n",
       " ('panca', [0, 1]),\n",
       " ('capra', [0, 1]),\n",
       " ('campa', [0]),\n",
       " ('sotto', [1]),\n",
       " ('crepa', [1])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverted index (sentence-based offset)\n",
    "rddCapra. \\\n",
    "  zipWithIndex(). \\\n",
    "  flatMap(lambda kv : [(x,kv[1]) for x in kv[0].split(\" \")]). \\\n",
    "  distinct(). \\\n",
    "  groupByKey(). \\\n",
    "  mapValues(lambda v: list(v)). \\\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fa65d30adec9ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sopra', [0]),\n",
       " ('la', [0, 1]),\n",
       " ('panca', [0, 1]),\n",
       " ('capra', [0, 1]),\n",
       " ('campa', [0]),\n",
       " ('sotto', [1]),\n",
       " ('crepa', [1])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverted index (sentence-based offset) alternative\n",
    "rddCapra.zipWithIndex(). \\\n",
    "  map(lambda kv : (kv[1],kv[0])). \\\n",
    "  flatMapValues(lambda x : x.split(\" \") ). \\\n",
    "  map(lambda kv : (kv[1],kv[0])). \\\n",
    "  distinct(). \\\n",
    "  groupByKey(). \\\n",
    "  mapValues(lambda v: list(v)). \\\n",
    "  collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c49c3689d65e2",
   "metadata": {},
   "source": [
    "## 101-3 Extra Spark jobs\n",
    "\n",
    "Implement the following job.\n",
    "\n",
    "- Co-occurrence count: count the number of co-occurrences in the text. A co-occurrence is defined as \"two distinct words appearing in the same line\".\n",
    "  - In the first line of the *capra* dataset, co-occurrences are:\n",
    "     - (sopra, la), (sopra, panca), (sopra, capra), (sopra, campa)\n",
    "     - (la, sopra), (la, panca), (la, capra), (la, campa) \n",
    "     - (panca, sopra), (panca, la), (panca, capra), (panca, campa)\n",
    "     - (capra, sopra), (capra, la), (capra, panca), (capra, campa)\n",
    "     - (campa, sopra), (campa, la), (campa, panca), (campa, capra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
