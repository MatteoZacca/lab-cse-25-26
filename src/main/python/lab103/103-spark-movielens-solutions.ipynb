{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99b6b25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:34:09.444324Z",
     "iopub.status.busy": "2022-02-28T15:34:09.441785Z",
     "iopub.status.idle": "2022-02-28T15:34:10.302913Z",
     "shell.execute_reply": "2022-02-28T15:34:10.302209Z",
     "shell.execute_reply.started": "2022-02-28T15:34:09.444282Z"
    }
   },
   "source": [
    "# 103 Spark - Movielens\n",
    "\n",
    "The goal of this lab is to run some analysis on a different dataset, [MovieLens](https://grouplens.org/datasets/movielens/).\n",
    "\n",
    "- Scala\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "    - [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "    - [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "- Python\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/3.5.0/rdd-programming-guide.html)\n",
    "    - [All RDD APIs](https://spark.apache.org/docs/3.5.0/api/python/reference/api/pyspark.RDD.html)\n",
    "\n",
    "**Download the dataset** from [here](https://big.csr.unibo.it/downloads/bigdata/ml-dataset.zip), unzip it and put it in the ```datasets/big``` folder.\n",
    "\n",
    "- ml-movies.csv (<u>movieId</u>:Long, title:String, genres:String) \n",
    "    - genres are separated by pipelines  (e.g., \"comedy|drama|action\")\n",
    "    - each movie is associated with many ratings\n",
    "\n",
    "- ml-ratings.csv (<u>userId</u>:Long, <u>movieId</u>:Long, rating:Double, year:Int)\n",
    "    - each rating is associated with many tags\n",
    "    - ml-ratings-sample.csv is a small sample of ml-ratings.csv, useful for developing\n",
    "- ml-tags.csv (<u>userId</u>:Long, <u>movieId</u>:Long, <u>tag</u>:String, year:Int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b673a91143a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7cd9f089ddf0:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Local Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Local Spark>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Local Spark\") \\\n",
    "    .config('spark.ui.port', '4040') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6297e3f5-17d3-44ba-a06c-8b1acf0ca078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_datasets = \"../../../../datasets/big/\"\n",
    "\n",
    "path_ml_movies = path_to_datasets + \"ml-movies.csv\"\n",
    "path_ml_ratings = path_to_datasets + \"ml-ratings.csv\" # switch to ml-ratings-sample.csv for development, but use the full one for optimization evaluations!\n",
    "path_ml_tags = path_to_datasets + \"ml-tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e643e27d-b710-43cb-bc3d-7bca65e93b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "class MovieLensParser:\n",
    "    no_genres_listed = \"(no genres listed)\"\n",
    "    comma_regex = re.compile(r',(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)')\n",
    "    pipe_regex = re.compile(r'\\|(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)')\n",
    "    quotes = '\"'\n",
    "\n",
    "    @staticmethod\n",
    "    def year_from_timestamp(timestamp: str) -> int:\n",
    "        \"\"\"Convert from timestamp (string) to year (int).\"\"\"\n",
    "        ts = int(timestamp.strip())\n",
    "        return datetime.utcfromtimestamp(ts).year\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_movie_line(line: str) -> Optional[Tuple[int, str, str]]:\n",
    "        \"\"\"Parse a movie record into (movieId, title, genres).\"\"\"\n",
    "        try:\n",
    "            parts = MovieLensParser.comma_regex.split(line)\n",
    "            title = parts[1].strip()\n",
    "            if title.startswith(MovieLensParser.quotes):\n",
    "                title = title[1:]\n",
    "            if title.endswith(MovieLensParser.quotes):\n",
    "                title = title[:-1]\n",
    "            return (int(parts[0].strip()), title, parts[2].strip())\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_rating_line(line: str) -> Optional[Tuple[int, int, float, int]]:\n",
    "        \"\"\"Parse a rating record into (userId, movieId, rating, year).\"\"\"\n",
    "        try:\n",
    "            parts = MovieLensParser.comma_regex.split(line)\n",
    "            year = MovieLensParser.year_from_timestamp(parts[3])\n",
    "            return int(parts[0].strip()), int(parts[1].strip()), float(parts[2].strip()), year\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_tag_line(line: str) -> Optional[Tuple[int, int, str, int]]:\n",
    "        \"\"\"Parse a tag record into (userId, movieId, tag, year).\"\"\"\n",
    "        try:\n",
    "            parts = MovieLensParser.comma_regex.split(line)\n",
    "            year = MovieLensParser.year_from_timestamp(parts[3])\n",
    "            return (int(parts[0].strip()), int(parts[1].strip()), parts[2].strip(), year)\n",
    "        except Exception:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e69ae6f-50f6-4e2f-9fe8-ff6d747e675f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddMovies = sc.textFile(path_ml_movies).map(MovieLensParser.parse_movie_line).filter(lambda x: x is not None)\n",
    "rddRatings = sc.textFile(path_ml_ratings).map(MovieLensParser.parse_rating_line).filter(lambda x: x is not None)\n",
    "rddTags = sc.textFile(path_ml_tags).map(MovieLensParser.parse_tag_line).filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dfbdfd-2ee7-4488-a95f-9f1f809e581c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T15:59:00.715374Z",
     "iopub.status.busy": "2022-02-28T15:59:00.715148Z",
     "iopub.status.idle": "2022-02-28T15:59:01.005430Z",
     "shell.execute_reply": "2022-02-28T15:59:01.004685Z",
     "shell.execute_reply.started": "2022-02-28T15:59:00.715351Z"
    },
    "tags": []
   },
   "source": [
    "## 103-1 Datasets exploration\n",
    "\n",
    "Cache the datasets and answer the following questions:\n",
    "\n",
    "- How many (distinct) users, movies, ratings, and tags?\n",
    "- How many (distinct) genres?\n",
    "- On average, how many ratings per user?\n",
    "- On average, how many ratings per movie?\n",
    "- On average, how many genres per movie?\n",
    "- What is the range of ratings?\n",
    "- Which years? (print an ordered list)\n",
    "- On average, how many ratings per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f07a5b9-baaf-4564-8988-33e23ced42ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddMoviesCached = rddMovies.cache()\n",
    "rddRatingsCached = rddRatings.cache()\n",
    "rddTagsCached = rddTags.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b647d309-6491-49c2-aa1c-8e682121d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 58098\n",
      "Number of ratings: 1000000\n",
      "Number of tags: 74702\n",
      "Number of users: 10073\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of movies: {rddMoviesCached.count()}\")\n",
    "print(f\"Number of ratings: {rddRatingsCached.count()}\")\n",
    "print(f\"Number of tags: {rddTags.map(lambda x: x[2]).distinct().count()}\")\n",
    "print(f\"Number of users: {rddRatingsCached.map(lambda x: x[0]).distinct().count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3d8ea09-72c5-4672-b863-a2f9598801d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genres: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of genres: \" + str(rddMoviesCached.flatMap(lambda x: x[2].split(\"|\")).distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e6c3741-d5b5-4c77-b813-7f4a3e276318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings per user: 99.27529038022436\n"
     ]
    }
   ],
   "source": [
    "avgRatPerUser = rddRatingsCached.\\\n",
    "    map(lambda x: (x[0],1)).\\\n",
    "    reduceByKey(lambda x,y: x+y).\\\n",
    "    map(lambda x: (x[1],1)).\\\n",
    "    reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "\n",
    "print(f\"Number of ratings per user: {(avgRatPerUser[0]/avgRatPerUser[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5aa8ef2b-2043-4bbd-82bf-b83a56227d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings per movie: 45.39058599246516\n"
     ]
    }
   ],
   "source": [
    "avgRatPerMovie = rddRatingsCached.\\\n",
    "    map(lambda x: (x[1],1)).\\\n",
    "    reduceByKey(lambda x,y: x+y).\\\n",
    "    map(lambda x: (x[1],1)).\\\n",
    "    reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "print(f\"Number of ratings per movie: {(avgRatPerMovie[0]/avgRatPerMovie[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92c746de-b72d-4389-ad55-7a98433e515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genres per movie: 1.8263451409687081\n"
     ]
    }
   ],
   "source": [
    "avgGenresPerMovie = rddMoviesCached.\\\n",
    "    map(lambda x: (x[0],x[2])).\\\n",
    "    mapValues(lambda x: len(x.split(\"|\"))).\\\n",
    "    reduceByKey(lambda x,y: x+y).\\\n",
    "    map(lambda x: (x[1],1)).\\\n",
    "    reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "print(f\"Number of genres per movie: {(avgGenresPerMovie[0]/avgGenresPerMovie[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2d6b49a-9f31-4cdb-b7ec-49cc72d4e73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of ratings: 0.5 to 5.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Range of ratings: {rddRatingsCached.map(lambda x: x[2]).min()} to {rddRatingsCached.map(lambda x: x[2]).max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "081f7809-46bd-4a9e-b724-b91e2afec778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered list of years:\n",
      "[1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ordered list of years:\")\n",
    "print(sorted(rddRatingsCached.map(lambda x: x[3]).distinct().collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc00fae6-8ade-474c-8357-1975c925a84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings per year: 43478.260869565216\n"
     ]
    }
   ],
   "source": [
    "avgRatPerYear = rddRatingsCached.\\\n",
    "    map(lambda x: (x[3],1)).\\\n",
    "    reduceByKey(lambda x,y: x+y).\\\n",
    "    map(lambda x: (x[1],1)).\\\n",
    "    reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]))\n",
    "print(f\"Number of ratings per year: {(avgRatPerYear[0]/avgRatPerYear[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4016ac-cb34-48d0-a45c-29122e5fa59a",
   "metadata": {},
   "source": [
    "## 103-2 Compute the average rating for each movie\n",
    "\n",
    "- Export the result to a file\n",
    "- Do not start from cached RDDs\n",
    "- Evaluate:\n",
    "  - Join-and-Aggregate\n",
    "  - Aggregate-and-Join\n",
    "  - Aggregate-and-BroadcastJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feb49547-58f9-4994-929a-da867e2e4cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_output_avgRatPerMovie = \"../../../../output/avgRatPerMovie\"\n",
    "# rdd.coalesce(1).toDF().write.format(\"csv\").mode('overwrite').option(\"header\", \"true\").save(path_output_avgRatPerMovie)\n",
    "\n",
    "for (id, rdd) in sc._jsc.getPersistentRDDs().items():         \n",
    "    rdd.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4fdb9c-7a73-43a0-a121-fe98dc71ea02",
   "metadata": {},
   "source": [
    "### Join-and-Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35060678-a714-4871-a0ee-bd6d1149c2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddMoviesKV = rddMovies.map(lambda x: (x[0],x[1]))\n",
    "avgRatPerMovie = rddRatings.\\\n",
    "    map(lambda x: (x[1],x[2])).\\\n",
    "    join(rddMoviesKV).\\\n",
    "    map(lambda x: ((x[0],x[1][1]),(x[1][0],1)) ).\\\n",
    "    reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).\\\n",
    "    map(lambda x: (x[0][0], x[0][1], x[1][0]/x[1][1], x[1][1])).\\\n",
    "    coalesce(1).\\\n",
    "    toDF().write.format(\"csv\").mode('overwrite').option(\"header\", \"true\").save(path_output_avgRatPerMovie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a78f233f9cdaf",
   "metadata": {},
   "source": [
    "### Aggregate-and-Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45bddac2-b5b0-4eee-b34d-312877a7262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddMoviesKV = rddMovies.map(lambda x: (x[0],x[1]))\n",
    "avgRatPerMovie = rddRatings.\\\n",
    "    map(lambda x: (x[1],(x[2],1))).\\\n",
    "    reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).\\\n",
    "    mapValues(lambda x: (x[0]/x[1], x[1])).\\\n",
    "    join(rddMoviesKV).\\\n",
    "    map(lambda x: (x[0], x[1][1], x[1][0][0], x[1][0][1])).\\\n",
    "    coalesce(1).\\\n",
    "    toDF().write.format(\"csv\").mode('overwrite').option(\"header\", \"true\").save(path_output_avgRatPerMovie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887bbb2f-5b97-4918-ae8c-dd98f252a6e6",
   "metadata": {},
   "source": [
    "### Aggregate-and-BroadcastJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d17c7e50-802a-46e7-b522-2269e23c0085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddMoviesKV = rddMovies.map(lambda x: (x[0],x[1]))\n",
    "bRddMovies = sc.broadcast(rddMoviesKV.collectAsMap())\n",
    "avgRatPerMovie = rddRatings.\\\n",
    "    map(lambda x: (x[1],(x[2],1))).\\\n",
    "    reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).\\\n",
    "    mapValues(lambda x: (x[0]/x[1], x[1])).\\\n",
    "    map(lambda x: (x[0],bRddMovies.value.get(x[0]),x[1][0],x[1][1])).\\\n",
    "    coalesce(1).\\\n",
    "    toDF().write.format(\"csv\").mode('overwrite').option(\"header\", \"true\").save(path_output_avgRatPerMovie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff452c0-3cec-4276-a3ec-ecf21b5583aa",
   "metadata": {},
   "source": [
    "Broadcasting does not improve performances in this case, because the join operation in the aggregation-before-join job is done on a limited amount of records, thus the shuffle operation was already quite fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07050d2-4447-4765-814d-2cd0ff1402c1",
   "metadata": {},
   "source": [
    "## 103-3 Compute the average rating for each genre\n",
    "\n",
    "Two possible workflows:\n",
    "\n",
    "1. Pre-aggregation (3 shuffles)\n",
    "\n",
    "  - Aggregate ratings by movieId\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres\n",
    "  \n",
    "2. Join & aggregate (2 shuffles)\n",
    "\n",
    "  - Join with movies and map to genres\n",
    "  - Aggregate by genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "191a8f82-2006-49a6-9a99-9de6638df74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_output_avgRatPerGenre = \"../../../../output/avgRatPerGenre\"\n",
    "\n",
    "for (id, rdd) in sc._jsc.getPersistentRDDs().items():         \n",
    "    rdd.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5566e3b-b6f8-4e07-83e2-db72a1995f27",
   "metadata": {},
   "source": [
    "Which is better?\n",
    "\n",
    "1. Pre-aggregation (3 shuffles)\n",
    "\n",
    "  - Aggregate ratings by movieId\n",
    "    - Input: 724MB (there are 28M ratings, it's ~26B per rating)\n",
    "    - Output: ~1.5MB (there are 58K movies)\n",
    "  - Join with movies and map to genres\n",
    "    - Input: ~1.5MB + 2.7MB (there are 58K movies, it's ~47B per movie)\n",
    "    - Output: ~6MB (considering 47B per record and 2 genres per movie)\n",
    "  - Aggregate by genres\n",
    "    - Input: ~6MB\n",
    "    - Output: ~1KB (considering 47B per record and that there are 20 genres)\n",
    "  \n",
    "2. Join & aggregate (2 shuffles)\n",
    "\n",
    "  - Join with movies and map to genres\n",
    "    - Input: 724MB + 2.7MB\n",
    "      - Actually lower due to serialization and \"column pruning\"\n",
    "    - Output: ~1.4GB (considering 47B per record and 2 genres per movie)\n",
    "      - Actually much lower due to map-side aggregation (i.e., combining) automatically done by Spark\n",
    "  - Aggregate by genres\n",
    "    - Input: ~1.4GB\n",
    "    - Output: ~1KB\n",
    "\n",
    "Let's verify it by executing them and looking at the execution plans at [localhost:4040](localhost:4040)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "024f80a2-faae-4174-81ff-410f6ab4e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddMoviesKV = rddMovies.map(lambda x: (x[0],x[2])).flatMapValues(lambda x: x.split(\"|\"))\n",
    "rddRatings.\\\n",
    "    map(lambda x: (x[1],(x[2],1))).\\\n",
    "    reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).\\\n",
    "    join(rddMoviesKV).\\\n",
    "    map(lambda x: (x[1][1],(x[1][0][0],x[1][0][1]))).\\\n",
    "    reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).\\\n",
    "    map(lambda x: (x[0], x[1][0]/x[1][1], x[1][1])).\\\n",
    "    coalesce(1).\\\n",
    "    toDF().write.format(\"csv\").mode('overwrite').save(path_output_avgRatPerGenre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6be271d-b46c-470b-a3c1-6159e705d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddMoviesKV = rddMovies.map(lambda x: (x[0],x[2])).flatMapValues(lambda x: x.split(\"|\"))\n",
    "rddRatings.\\\n",
    "    map(lambda x: (x[1],x[2])).\\\n",
    "    join(rddMoviesKV).\\\n",
    "    map(lambda x: (x[1][1],(x[1][0],1))).\\\n",
    "    reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).\\\n",
    "    map(lambda x: (x[0], x[1][0]/x[1][1], x[1][1])).\\\n",
    "    coalesce(1).\\\n",
    "    toDF().write.format(\"csv\").mode('overwrite').save(path_output_avgRatPerGenre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230eddab-7104-43bf-9067-b5056925c085",
   "metadata": {},
   "source": [
    "The first one is definetely better!\n",
    "\n",
    "### Pay attention\n",
    "\n",
    "In the pre-aggregation pattern, be careful not doing the \"average of the average\", but computing the average only at the end - otherwise, the results won't match.\n",
    "\n",
    "However, it really depends on what you want to achieve: for a given genre, assume that you have 1 movie with 1000 good ratings (rated 5) and 100 movies with bad ratings (rated 1). What should the average rating of the genre be?\n",
    "- If popular movies should weigh more, you should just do a single average on all the ratings: the result should then be (1000\\*5 + 100\\*1) / (1000 + 100) = 4.64.\n",
    "- If all movies should weigh the same, then you should do the \"average of the average\": the first movie has an average rating of 5, all others an average rating of 1, so it becomes (5\\*1 + 100\\*1) / 101 = 1.04.\n",
    "\n",
    "Results can vary significantly; think about it when doing statistical analyses!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
